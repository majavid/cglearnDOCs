<!DOCTYPE html>
<html>
  <head>
    <title>cglearn Documentation</title>
    <style>
      body {
        display: flex;
        flex-direction: column;
        min-height: 100vh;
        margin: 0;
        padding: 0;
        font-family: Arial, sans-serif;
      }

      header {
        background-color: #333;
        color: #fff;
        padding: 20px;
        text-align: center;
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
      }

      h1 {
        margin-top: 0;
      }

      main {
        background-color: #f1f1f1;
        margin-top: 80px;
        overflow-y: auto;
      }

      nav {
        width: 20%;
        background-color: #fff;
        padding: 20px;
        box-shadow: 0 0 5px rgba(0, 0, 0, 0.2);
        position: fixed;
        top: 100px;
        bottom: 0;
        overflow-y: auto;
      }

      ul {
        list-style: none;
        padding: 0;
        margin: 0;
      }

      li {
        margin-bottom: 10px;
      }

      a {
        color: #333;
        text-decoration: none;
        transition: color 0.3s ease;
      }

      a:hover {
        color: #666;
      }

      section {
        padding: 20px;
      }

      section h1 {
        margin-bottom: 20px;
        color: #333;
      }

      section:not(:last-child) {
        border-bottom: 1px solid #ccc;
        padding-bottom: 20px;
        margin-bottom: 20px;
      }

      #content {
        margin-left: 22%;
      }

      p {
        margin: 0 0;
        padding: 10px;
      }

      pre {
        background-color: #fff;
        padding: 10px;
        border-radius: 4px;
        white-space: pre-wrap;
        overflow-x: auto;
      }

      .arg_name {
        color: darkgreen;
      }

      .arguments-table {
        width: 100%;
        border-collapse: collapse;
        margin-left: 5px;
      }

      .arguments-table th,
      .arguments-table td {
        border: 1px solid #ccc;
        padding: 5px;
      }

      .arguments-table th {
        background-color: #f1f1f1;
        font-weight: bold;
        text-align: left;
        border: none;
      }

      .arguments-table td {
        border: none;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Library Documentation</h1>
    </header>

    <main>
      <nav>
        <h2>Library Functions</h2>
        <ul>
          <li><a href="#comp_pat">comp_pat</a></li>
          <li><a href="#comp_skel">comp_skel</a></li>
          <li><a href="#ischaingraph">is_chain_graph</a></li>
          <li><a href="#moralize">get_moralize_matrix</a></li>
          <li><a href="#skeleton">skeleton</a></li>
          <li><a href="#isseparated">is_separated</a></li>
          <li><a href="#istriangulated">is_triangulated</a></li>
          <li><a href="#triangulate">triangulate</a></li>
          <li><a href="#ugtojtree">ug_to_jtree</a></li>
          <li><a href="#get_uig_norm">get_uig_norm</a></li>
          <li><a href="#gaussCItest">gaussCItest</a></li>
          <li><a href="#gaussian_pc_learn">gaussian_pc_learn</a></li>
          <li><a href="#learn_skeleton_norm">learn_skeleton_norm</a></li>
          <li><a href="#gaussian_skeleton_mkb">gaussian_skeleton_mkb</a></li>
          <li><a href="#get_pattern_matrix">get_pattern_matrix</a></li>
          <!-- Add more function links here -->
        </ul>
      </nav>

      <section id="content">
        <section id="comp_pat">
          <h1 class="functionName">comp_pat</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Compares a (learned) chain graph pattern to the (supposed) true
            pattern. The two patterns should have the same vertex set in order
            for the function to return a meaningful result.
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">comp_pat(truepat, pat)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>truepat</td>
              <td>the adjacency matrix of the true pattern.</td>
            </tr>
            <tr>
              <td>pat</td>
              <td>
                the adjacency matrix of the pattern to be compared with the true
                one.
              </td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function simply compares two np.arrays and finds the differences
            in provided patterns. It also computers error measures(TPR, FPR,
            ACC, etc)
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>trueArrows</td>
              <td>Number of true arrows</td>
            </tr>
            <tr>
              <td>missingArrows</td>
              <td>Number of missing arrows in the learned pattern</td>
            </tr>
            <tr>
              <td>extraArrows</td>
              <td>Number of extra arrows in the learned pattern</td>
            </tr>
            <tr>
              <td>shd</td>
              <td>Structural Hamming Distance</td>
            </tr>
            <tr>
              <td>tpr</td>
              <td>TPR</td>
            </tr>
            <tr>
              <td>tdr</td>
              <td>TDR</td>
            </tr>
            <tr>
              <td>fpr</td>
              <td>FPR</td>
            </tr>
            <tr>
              <td>acc</td>
              <td>Accuracy</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[1, 1, 1],[0, 0, 0],[0, 0, 0]])
matrix2 = np.array([[0, 0, 0],[0, 0, 0],[1, 1, 1]])
resultDict = comp_pat(matrix1, matrix2)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Tsamardinos, I., Brown, L., and Aliferis, C. (2006). The max-min
            hill-climbing Bayesian network structure learning algorithm. Mach.
            Learn., 65(1):31-78.
          </p>
        </section>

        <section id="comp_skel">
          <h1 class="functionName">comp_skel</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Compares a (learned) chain graph skeleton to the (supposed) true
            skeleton. The two patterns should have the same vertex set in order
            for the function to return a meaningful result.
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">comp_skel(trueskel, skel)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>trueskel</td>
              <td>the adjacency matrix of the true skeleton.</td>
            </tr>
            <tr>
              <td>skel</td>
              <td>
                the adjacency matrix of the skeleton to be compared with the
                true one.
              </td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function simply compares two np.arrays and finds the differences
            in provided skeletons. It also computers error measures(TPR, FPR,
            ACC, etc)
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>numTrueEdges</td>
              <td>Number of true edges</td>
            </tr>
            <tr>
              <td>missingEdges</td>
              <td>Number of missing edges in the learned skeleton</td>
            </tr>
            <tr>
              <td>extraEdges</td>
              <td>Number of extra edges in the learned skeleton</td>
            </tr>
            <tr>
              <td>shd</td>
              <td>Structural Hamming Distance</td>
            </tr>
            <tr>
              <td>tpr</td>
              <td>TPR</td>
            </tr>
            <tr>
              <td>tdr</td>
              <td>TDR</td>
            </tr>
            <tr>
              <td>fpr</td>
              <td>FPR</td>
            </tr>
            <tr>
              <td>acc</td>
              <td>Accuracy</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
matrix2 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
resultDict = comp_skeleton(matrix1, matrix2)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Tsamardinos, I., Brown, L., and Aliferis, C. (2006). The max-min
            hill-climbing Bayesian network structure learning algorithm. Mach.
            Learn., 65(1):31-78.
          </p>
        </section>

        <section id="ischaingraph">
          <h1 class="functionName">is_chain_graph</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">Checks if a given graph is a chain graph.</p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">is_chain_graph(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function tries to find a partially directed cycle. If found, it
            is not a chain graph
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>Result</td>
              <td>True/False</td>
            </tr>
            <tr>
              <td>cycle_path</td>
              <td>If there is a cycle, it is returned as a list of vertices</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result,cycle = is_chain_graph(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Cowell, R. G., Dawid, A. P., Lauritzen, S. L. and Spiegelhalter, D.
            J. (1999) Probabilistic Networks and Expert Systems.
            Springer-Verlag, New York.
          </p>
        </section>

        <section id="moralize">
          <h1 class="functionName">get_moralize_matrix</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Converts chain graph into its moralized graph
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">get_moralize_matrix(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the chain graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function joins all complex spouse with undirected edge and then
            converts all arrows into lines
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>Result</td>
              <td>adjacency matrix of the moral graph</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = get_moralize_matrix(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Lauritzen, S. L. (1996). Graphical Models. Clarendon Press, Oxford.
          </p>
        </section>

        <section id="skeleton">
          <h1 class="functionName">skeleton</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">Returns skeleton of a graph</p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">skeleton(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function converts all arrows into lines
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>Result</td>
              <td>adjacency matrix of the skeleton</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = skeleton(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content"></p>
        </section>

        <section id="isseparated">
          <h1 class="functionName">is_separated</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">Returns skeleton of a graph</p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">
            is_separated(setA, setB, setSeparator, adj_matrix)
          </p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>setA</td>
              <td>first set of vertices</td>
            </tr>
            <tr>
              <td>setB</td>
              <td>sevond set of vertices</td>
            </tr>
            <tr>
              <td>setSeparator</td>
              <td>
                set of vertices that based on which we want to check
                C-separation of setA and setB
              </td>
            </tr>
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function checks if vertices from set A are C-separated from
            vertcies from setB given a set, setSeparator(can be empty)
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>Result</td>
              <td>True/False</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = is_separated({0}, {1}, {2}, matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Lauritzen, S. L. (1996). Graphical Models. Clarendon Press, Oxford.
            Studeny, M. and Bouckaert, R. R. (1998). On chain graph models for
            description of conditional independence structures. Annals of
            Statistics 26 1434-1495.
          </p>
        </section>

        <section id="istriangulated">
          <h1 class="functionName">is_triangulated</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Performs a maximum cardinality search on an undirected graph to
            determine whether it is triangulated.
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">is_triangulated(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the undirected graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function checks if given undirected matrix is triangulated or
            not and also returns the perfect numbering of vertices based on
            simple linear-time algorithms to test chordality of graphs given by
            Tarjan, R. E. and Yannakakis. See referecnce for details
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>is.triangulated</td>
              <td>
                True/False - a logical value indicating whether the input graph
                is triangulated or not.
              </td>
            </tr>
            <tr>
              <td>perfect.numbering</td>
              <td>a perfect numbering of the vertices.</td>
            </tr>
            <tr>
              <td>card</td>
              <td>
                number of unlabeled neighbors when labeling each variable, with
                order compatible to the perfect numbering.
              </td>
            </tr>
            <tr>
              <td>pi.record</td>
              <td>
                a record of unlabeled neighbors during the execution of the
                algorithm.
              </td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
resultDict = is_triangulated(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Tarjan, R. E. and Yannakakis, M. (1984). Simple linear-time
            algorithms to test chordality of graphs, test acyclicity of
            hypergraphs, and selectively reduce acyclic hypergraphs. SIAM
            Journal on Computing, 13, 566-79.
          </p>
        </section>

        <section id="triangulate">
          <h1 class="functionName">triangulate</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Triangulates an undirected graph to a chordal graph.
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">triangulate(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the undirected graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            This function coverts a graph into triangulated graph. For this
            purpose it use One Step Look Ahead Triangulation algorithm (see
            references)
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the triangulated graph.</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = triangulate(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Cowell, R. G., Dawid, A. P., Lauritzen, S. L. and Spiegelhalter, D.
            J. (1999) Probabilistic Networks and Expert Systems.
            Springer-Verlag, New York.
          </p>
        </section>

        <section id="ugtojtree">
          <h1 class="functionName">ug_to_jtree</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Constructs a junction tree for an undirected graph.
          </p>
          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">ug_to_jtree(adj_matrix)</p>
          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adj_matrix</td>
              <td>the adjacency matrix of the undirected graph.</td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            This function and its helpers implement the junction tree
            construction algorithm described in detail in Section 4.3 and 4.4 of
            Cowell, et al (1999).
          </p>
          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>result</td>
              <td>An object of class SepTree</td>
            </tr>
          </table>
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = ug_to_jtree(matrix1)
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Cowell, R. G., Dawid, A. P., Lauritzen, S. L. and Spiegelhalter, D.
            J. (1999) Probabilistic Networks and Expert Systems.
            Springer-Verlag, New York.
          </p>
        </section>

        <section id="septree">
          <h1 class="functionName">SepTree</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Objects representing separation tree as described in Xie, Geng and
            Zhao (2006) and Ma, Xie and Geng (2008), which includes junction
            tree of cliques as a special case.
          </p>
          <!-- <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">ug_to_jtree(adj_matrix)</p> -->
          <p class="args_header"><strong>Data members:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>tree_struct</td>
              <td>the adjacency matrix of the junction tree.</td>
            </tr>
            <tr>
              <td>cliques</td>
              <td>the list of cliques on the junction tree.</td>
            </tr>
            <tr>
              <td>separators</td>
              <td>
                the list of separators on the junction tree, each element on the
                list has two components: the separator compoenent is the set of
                graph vertices in the separator and edge is the edge on the tree
                that the separator is attahced to
              </td>
            </tr>
          </table>
          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            This function and its helpers implement the junction tree
            construction algorithm described in detail in Section 4.3 and 4.4 of
            Cowell, et al (1999).
          </p>
          <!-- <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>result</td>
              <td>An object of class SepTree</td>
            </tr>
          </table> -->
          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>matrix1 = np.array([[0, 1, 1],[1, 0, 1],[0, 1, 1]])
result = ug_to_jtree(matrix1)
# result will be an object of SepTree
          </code></pre>
          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>
          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Ma, Z., Xie, X. and Geng, Z. (2008). Structural learning of chain
            graphs via decomposition. J. Mach. Learn. Res., 9, 2847-2880. Xie,
            X., Geng, Z. and Zhao, Q. (2006). Decomposition of structural
            learning about directed acyclic graphs. Artif. Intell., 170,
            422-439.
          </p>
        </section>

        <section id="get_uig_norm">
          <h1 class="functionName">get_uig_norm</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Learns an undirected independence graph from a given data set. The
            data are assumed to be normally distributed.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">get_uig_norm(data, p_value)</p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>data</td>
              <td>
                The data matrix with rows corresponding to observations and
                columns corresponding to random variables.
              </td>
            </tr>
            <tr>
              <td>p_value</td>
              <td>
                The thresholding p-value for each conditional independence test.
              </td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function learns an undirected independence graph by computing
            the partial correlations between variables based on the provided
            data matrix. It uses a thresholding p-value to determine the
            existence of edges in the graph.
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <p class="value_content">
            The function returns the adjacency matrix of the learned undirected
            independence graph.
          </p>

          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>data = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])
p_value = 0.05
adj_matrix = get_uig_norm(data, p_value)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Lauritzen, S. L. (1996). Graphical Models. Clarendon Press, Oxford.
          </p>
        </section>

        <section id="gaussCItest">
          <h1 class="functionName">gaussCItest</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Performs the Gaussian conditional independence test between two
            variables with a set of conditioning variables.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">gaussCItest(x, y, S, stuffStat)</p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>x, y</td>
              <td>Indices of the variables for which to perform the test.</td>
            </tr>
            <tr>
              <td>S</td>
              <td>Set of conditioning variables.</td>
            </tr>
            <tr>
              <td>stuffStat</td>
              <td>Dictionary containing relevant statistical information.</td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function performs a Gaussian conditional independence test
            between variables `x` and `y`, given a set of conditioning variables
            `S`. It calculates the test statistic `z` based on the statistical
            information provided in the `stuffStat` dictionary. It then computes
            the p-value for the test
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <p class="value_content">
            The function returns the p-value of the Gaussian conditional
            independence test.
          </p>

          <p class="example_header"><strong>Example:</strong></p>
          <pre class="example_content"><code>x = 0
y = 1
S = [2, 3]
stuffStat = {'C': [0.2, 0.3, 0.5, 0.1], 'n': 100}
p_value = gaussCItest(x, y, S, stuffStat)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Whittaker, J. (1990). Graphical Models in Applied Mathematical
            Multivariate Statistics. John Wiley and Sons, Chichester, England.
          </p>
        </section>

        <section id="gaussian_pc_learn">
          <h1 class="functionName">gaussian_pc_learn</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Learns the structure of a directed acyclic graph (DAG) using the PC
            algorithm for Gaussian data.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">
            gaussian_pc_learn(cov, n, p_value, vertexNames=[])
          </p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>cov</td>
              <td>The covariance matrix of the data.</td>
            </tr>
            <tr>
              <td>n</td>
              <td>The number of observations in the data.</td>
            </tr>
            <tr>
              <td>p_value</td>
              <td>The threshold p-value for conditional independence tests.</td>
            </tr>
            <tr>
              <td>vertexNames</td>
              <td>(Optional) List of names for each vertex in the graph.</td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function implements the PC algorithm for learning the structure
            of a directed acyclic graph (DAG) from Gaussian data. It starts with
            a complete undirected graph and iteratively removes edges based on
            conditional independence tests. The algorithm considers zero-order,
            first-order, second-order, and so on conditional independence
            relations to thin the graph. The resulting graph represents the
            learned DAG structure.
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>amat</td>
              <td>The adjacency matrix of the learned DAG.</td>
            </tr>
            <tr>
              <td>sep_pairs</td>
              <td>
                A list of separation pairs representing d-separation
                relationships in the learned DAG. Each separation pair contains
                the vertices and separation set for d-separation.
              </td>
            </tr>
          </table>

          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>cov_matrix = np.array([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])
n_observations = 1000
p_value_threshold = 0.05
vertex_names = ['A', 'B', 'C']
result = gaussian_pc_learn(cov_matrix, n_observations, p_value_threshold, vertex_names)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Mohammad Ali Javidian, Marco Valtorta, and Pooyan Jamshidi. "An
            Order-Independent Algorithm for Learning Chain Graphs" Proceedings
            of the 34th International Florida Artificial Intelligence Research
            Society Conference (FLAIRS-34), 2021
          </p>
        </section>

        <section id="learn_skeleton_norm">
          <h1 class="functionName">learn_skeleton_norm</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Learns the skeleton of a graphical model using the PC algorithm for
            Gaussian data.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">
            learn_skeleton_norm(tree: SepTree, cov, n, p_value, drop=True)
          </p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>tree</td>
              <td>
                A SepTree object representing the tree structure of the
                graphical model.
              </td>
            </tr>
            <tr>
              <td>cov</td>
              <td>The covariance matrix of the data.</td>
            </tr>
            <tr>
              <td>n</td>
              <td>An integer specifying the sample size.</td>
            </tr>
            <tr>
              <td>p_value</td>
              <td>A significance level used in statistical tests.</td>
            </tr>
            <tr>
              <td>drop</td>
              <td>
                (Optional) A boolean indicating whether to drop edges or not
                (default is True).
              </td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function implements the PC algorithm for learning the skeleton
            of a graphical model from Gaussian data. It starts with a given
            SepTree object representing the tree structure of the graphical
            model. The function then learns local undirected graphs within each
            clique of the tree, and then removes edges based on conditional
            independence tests using the PC algorithm. The resulting graph
            represents the skeleton of the graphical model.
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>amat</td>
              <td>The adjacency matrix of the learned skeleton.</td>
            </tr>
            <tr>
              <td>sep_pairs</td>
              <td>
                A list of separation pairs representing d-separation
                relationships in the learned skeleton. Each separation pair
                contains the vertices and separation set for d-separation.
              </td>
            </tr>
          </table>

          <p class="example_header"><strong>Example:</strong></p>
          <pre class="example_content"><code>tree_structure = SepTree(...)
cov_matrix = np.array([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])
n_observations = 1000
p_value_threshold = 0.05
result = learn_skeleton_norm(tree_structure, cov_matrix, n_observations, p_value_threshold)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content"></p>
        </section>

        <section id="gaussian_skeleton_mkb">
          <h1 class="functionName">gaussian_skeleton_mkb</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Performs skeleton learning by iteratively removing edges based on
            conditional independence tests for Gaussian data.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">gaussian_skeleton_mkb(cov, n, p_value)</p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>cov</td>
              <td>The covariance matrix of the variables.</td>
            </tr>
            <tr>
              <td>n</td>
              <td>
                An integer specifying the number of sample cases (number of rows
                in the data).
              </td>
            </tr>
            <tr>
              <td>p_value</td>
              <td>A threshold p-value for conditional independence tests.</td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function performs skeleton learning by iteratively removing
            edges based on conditional independence tests. It starts with a
            given covariance matrix of the variables and performs Phase 1 of the
            MKB (Markov blanket) algorithm to learn the Markov blankets for each
            variable. It then removes edges between variables that are not in
            each other's Markov blankets. Finally, it applies the PC algorithm
            to further remove edges based on conditional independence tests
            using the given p-value threshold. The resulting graph represents
            the learned skeleton of the graphical model.
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>amat</td>
              <td>The adjacency matrix of the learned skeleton.</td>
            </tr>
            <tr>
              <td>sep_pairs</td>
              <td>
                A list of separation pairs indicating the separation sets
                between variables. Each separation pair contains the vertices
                and separation set for d-separation.
              </td>
            </tr>
          </table>

          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>cov_matrix = np.array([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])
n_observations = 1000
p_value_threshold = 0.05
result = gaussian_skeleton_mkb(cov_matrix, n_observations, p_value_threshold)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Mohammad Ali Javidian, Marco Valtorta, and Pooyan Jamshidi.
            "Learning LWF Chain Graphs: A Markov Blanket Discovery Approach"
            Proceedings of the Thirty Sixth Conference on Uncertainty in
            Artificial Intelligence (UAI-2020), pages: 1069-1078, 2020.
            <br /><br />Margaritis, D., and Thrun, S. 1999. Bayesian network
            induction via local neighborhoods. In Proceedings of the NIPS’99,
            505–511.
          </p>
        </section>

        <section id="get_pattern_matrix">
          <h1 class="functionName">get_pattern_matrix</h1>

          <p class="desc_header"><strong>Description:</strong></p>
          <p class="desc_content">
            Generates the pattern matrix from the adjacency matrix of a directed
            graph.
          </p>

          <p class="usage_header"><strong>Usage:</strong></p>
          <p class="usage_content">get_pattern_matrix(adjacency_matrix)</p>

          <p class="args_header"><strong>Arguments:</strong></p>
          <table class="arguments-table">
            <tr>
              <td>adjacency_matrix</td>
              <td>
                A NumPy array representing the adjacency matrix of the directed
                graph.
              </td>
            </tr>
          </table>

          <p class="details_header"><strong>Details:</strong></p>
          <p class="details_content">
            The function generates the pattern matrix by finding all the edges
            that are part of at least one minimal complex in the directed graph.
            The function then converts the input adjacency matrix into the
            adjacency matrix for the pattern by making all the remaining
            directional edges undirectional.
          </p>

          <p class="value_header"><strong>Value:</strong></p>
          <p class="value_content">
            Returns the pattern matrix as a NumPy array.
          </p>

          <p class="example_header"><strong>Example:</strong></p>
          <pre
            class="example_content"
          ><code>adjacency_matrix = np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])
pattern_matrix = get_pattern_matrix(adjacency_matrix)</code></pre>

          <p class="author_header"><strong>Author(s):</strong></p>
          <p class="author_content">Mohammad Ali Javidian and Shantanu Deore</p>

          <p class="references_header"><strong>References:</strong></p>
          <p class="references_content">
            Studeny, M. (1997). A recovery algorithm for chain graphs. Int. J.
            Approx. Reasoning, 17, 265-293.
          </p>
        </section>
      </section>

      <!-- Add more sections for additional functions -->
    </main>
  </body>
</html>
